{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU Language Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgColai1cruXJYW3hXl+Sr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohameddhameem/LearnPyTorch/blob/master/GRU_Language_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqduAs3MUwgh",
        "colab_type": "text"
      },
      "source": [
        "#GRU Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7jmj0qSU-uG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "276b9d60-d9c2-4fa5-949d-3e6e7d762b76"
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#Other essential libraries\n",
        "from collections import namedtuple\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, tensor, autograd\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daC0-ylDZ8FX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "c09aa4e8-994b-4f2e-9535-f752300eeb2a"
      },
      "source": [
        "!pip install -U gensim==3.7.1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim==3.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/6c93685bed0026b6a1cce55ab173f6b617f6db0d1325d25489c2fd43e711/gensim-3.7.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 126kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.1) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.1) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.1) (1.9.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.1) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.1) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.1) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.1) (1.11.15)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.1) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.1) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.1) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.1) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.1) (1.14.15)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.1) (0.9.4)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.1) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.7.0->gensim==3.7.1) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.7.0->gensim==3.7.1) (0.15.2)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.8.1\n",
            "    Uninstalling gensim-3.8.1:\n",
            "      Successfully uninstalled gensim-3.8.1\n",
            "Successfully installed gensim-3.7.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gensim"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYD2osi4aCd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffd32866-9d6f-420b-b13c-83db89b7b947"
      },
      "source": [
        "import gensim\n",
        "print(gensim.__version__)\n",
        "# gensim version has to be \n",
        "from gensim.corpora import Dictionary"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuJAcmzlVGgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d44b2f23-42c2-451a-99a2-d4b7ec707a18"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.set(rc={'figure.figsize':(12, 8)})\n",
        "#Set the random seed\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc3604dbfb0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7N7aLHsVV_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try: # Use the default NLTK tokenizer.\n",
        "    from nltk import word_tokenize, sent_tokenize \n",
        "    # Testing whether it works. \n",
        "    # Sometimes it doesn't work on some machines because of setup issues.\n",
        "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
        "except: # Use a naive sentence tokenizer and toktok.\n",
        "    import re\n",
        "    from nltk.tokenize import ToktokTokenizer\n",
        "    # See https://stackoverflow.com/a/25736515/610569\n",
        "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
        "    # Use the toktok tokenizer that requires no dependencies.\n",
        "    toktok = ToktokTokenizer()\n",
        "    word_tokenize = word_tokenize = toktok.tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXZdYfo7Vc4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import io #codecs\n",
        "\n",
        "\n",
        "# Text version of https://kilgarriff.co.uk/Publications/2005-K-lineer.pdf\n",
        "if os.path.isfile('language-never-random.txt'):\n",
        "    with io.open('language-never-random.txt', encoding='utf8') as fin:\n",
        "        text = fin.read()\n",
        "else:\n",
        "    #Lets try to download the file if its not available in the system\n",
        "    url = \"https://gist.githubusercontent.com/alvations/53b01e4076573fea47c6057120bb017a/raw/b01ff96a5f76848450e648f35da6497ca9454e4a/language-never-random.txt\"\n",
        "    text = requests.get(url).content.decode('utf8')\n",
        "    with io.open('language-never-random.txt', 'w', encoding='utf8') as fout:\n",
        "        fout.write(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZsMWvSIVfyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize the text.\n",
        "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in sent_tokenize(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lp_65S_VwUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KilgariffDataset(nn.Module):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "        \n",
        "        # Initialize the vocab \n",
        "        special_tokens = {'<pad>': 0, '<unk>':1, '<s>':2, '</s>':3}\n",
        "        self.vocab = Dictionary(texts)\n",
        "        self.vocab.patch_with_special_tokens(special_tokens)\n",
        "        \n",
        "        # Keep track of the vocab size.\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        \n",
        "        # Keep track of how many data points.\n",
        "        self._len = len(texts)\n",
        "        \n",
        "        # Find the longest text in the data.\n",
        "        self.max_len = max(len(txt) for txt in texts) \n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        vectorized_sent = self.vectorize(self.texts[index])\n",
        "        x_len = len(vectorized_sent)\n",
        "        # To pad the sentence:\n",
        "        # Pad left = 0; Pad right = max_len - len of sent.\n",
        "        pad_dim = (0, self.max_len - len(vectorized_sent))\n",
        "        vectorized_sent = F.pad(vectorized_sent, pad_dim, 'constant')\n",
        "        return {'x':vectorized_sent[:-1], \n",
        "                'y':vectorized_sent[1:], \n",
        "                'x_len':x_len}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self._len\n",
        "    \n",
        "    def vectorize(self, tokens, start_idx=2, end_idx=3):\n",
        "        \"\"\"\n",
        "        :param tokens: Tokens that should be vectorized. \n",
        "        :type tokens: list(str)\n",
        "        \"\"\"\n",
        "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
        "        # Lets just cast list of indices into torch tensors directly =)\n",
        "        \n",
        "        vectorized_sent = [start_idx] + self.vocab.doc2idx(tokens) + [end_idx]\n",
        "        return torch.tensor(vectorized_sent)\n",
        "    \n",
        "    def unvectorize(self, indices):\n",
        "        \"\"\"\n",
        "        :param indices: Converts the indices back to tokens.\n",
        "        :type tokens: list(int)\n",
        "        \"\"\"\n",
        "        return [self.vocab[i] for i in indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV6CAvpNX_0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2580e4a-220f-469f-fbe9-195c49275d55"
      },
      "source": [
        "kilgariff_data = KilgariffDataset(tokenized_text)\n",
        "len(kilgariff_data.vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1430"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCgj0LUYC4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "70732331-3303-4218-c9a0-4efcbc95e8bf"
      },
      "source": [
        "batch_size = 10\n",
        "dataloader = DataLoader(dataset=kilgariff_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for data_dict in dataloader:\n",
        "    # Sort indices of data in batch by lengths.\n",
        "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist()\n",
        "    data_batch = {name:_tensor[sorted_indices]\n",
        "                  for name, _tensor in data_dict.items()}\n",
        "    print(data_batch)\n",
        "    break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'x': tensor([[   2,  125,  738,  ...,    0,    0,    0],\n",
            "        [   2,  644,   48,  ...,    0,    0,    0],\n",
            "        [   2,   30,   58,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [   2, 1010,    4,  ...,    0,    0,    0],\n",
            "        [   2,   35, 1112,  ...,    0,    0,    0],\n",
            "        [   2,   45,    8,  ...,    0,    0,    0]]), 'y': tensor([[ 125,  738,   83,  ...,    0,    0,    0],\n",
            "        [ 644,   48,  104,  ...,    0,    0,    0],\n",
            "        [  30,   58,   69,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [1010,    4, 1011,  ...,    0,    0,    0],\n",
            "        [  35, 1112, 1257,  ...,    0,    0,    0],\n",
            "        [  45,    8, 1130,  ...,    0,    0,    0]]), 'x_len': tensor([98, 60, 48, 45, 24, 22, 18, 14, 13,  6])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLfIyLPMe_Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size, num_layers):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initialize the embedding layer with the \n",
        "        # - size of input (i.e. no. of words in input vocab)\n",
        "        # - no. of hidden nodes in the embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "        \n",
        "        # Initialize the GRU with the \n",
        "        # - size of the input (i.e. embedding layer)\n",
        "        # - size of the hidden layer \n",
        "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, batch_first=True)\n",
        "        \n",
        "        # Initialize the \"classifier\" layer to map the RNN outputs\n",
        "        # to the vocabulary. Remember we need to -1 because the \n",
        "        # vectorized sentence we left out one token for both x and y:\n",
        "        # - size of hidden_size of the GRU output.\n",
        "        # - size of vocabulary\n",
        "        self.classifier = nn.Linear(hidden_size, vocab_size)\n",
        "        \n",
        "    def forward(self, inputs, use_softmax=False, hidden=None):\n",
        "        # Look up for the embeddings for the input word indices.\n",
        "        embedded = self.embedding(inputs)\n",
        "        # Put the embedded inputs into the GRU.\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        \n",
        "        # Matrix manipulation magic.\n",
        "        batch_size, sequence_len, hidden_size = output.shape\n",
        "        # Technically, linear layer takes a 2-D matrix as input, so more manipulation...\n",
        "        output = output.contiguous().view(batch_size * sequence_len, hidden_size)\n",
        "        # Apply dropout.\n",
        "        output = F.dropout(output, 0.5)\n",
        "        # Put it through the classifier\n",
        "        # And reshape it to [batch_size x sequence_len x vocab_size]\n",
        "        output = self.classifier(output).view(batch_size, sequence_len, -1)\n",
        "        \n",
        "        return (F.softmax(output,dim=2), hidden) if use_softmax else (output, hidden)       \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK6u3J7jgZBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the hidden_size of the GRU \n",
        "embed_size = 12\n",
        "hidden_size = 10\n",
        "num_layers = 1\n",
        "\n",
        "_encoder = Generator(len(kilgariff_data.vocab), embed_size, hidden_size, num_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReRjHT6zggIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take a batch.\n",
        "batch_size = 15\n",
        "dataloader = DataLoader(dataset=kilgariff_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "_batch = next(iter(dataloader))\n",
        "_inputs, _lengths = _batch['x'], _batch['x_len']\n",
        "_targets = _batch['y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf-z2-E6gjdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "74131fa6-cbd1-44ab-9464-39ef4f9fa532"
      },
      "source": [
        "_output, _hidden = _encoder(_inputs)\n",
        "print('Output sizes:\\t', _output.shape)\n",
        "print('Input sizes:\\t', batch_size, kilgariff_data.max_len -1, len(kilgariff_data.vocab))\n",
        "print('Target sizes:\\t', _targets.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output sizes:\t torch.Size([15, 184, 1430])\n",
            "Input sizes:\t 15 184 1430\n",
            "Target sizes:\t torch.Size([15, 184])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgArcf93glzz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "204920e5-0f8b-401b-e26a-1dbf175e4410"
      },
      "source": [
        "_output.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 184, 1430])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr_xd0vjgpIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71bef1c0-7400-42be-c67f-ed2fbb48f073"
      },
      "source": [
        "_output[-1].shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([184, 1430])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp37wXuPgrkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5d7b87b-c890-44e8-f1be-56315e6db715"
      },
      "source": [
        "_, predicted_indices = torch.max(_output, dim=1)\n",
        "print(predicted_indices.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 1430])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rnZE9GFguHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7d4f36dd-38ea-42d7-b84a-cc84c798ee6f"
      },
      "source": [
        "_hyper = ['embed_size', 'hidden_size', 'num_layers',\n",
        "          'loss_func', 'learning_rate', 'optimizer', 'batch_size']\n",
        "Hyperparams = namedtuple('Hyperparams', _hyper)\n",
        "\n",
        "\n",
        "hyperparams = Hyperparams(embed_size=250, hidden_size=250, num_layers=1,\n",
        "                          loss_func=nn.CrossEntropyLoss,\n",
        "                          learning_rate=0.03, optimizer=optim.Adam, batch_size=245)\n",
        "\n",
        "hyperparams"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Hyperparams(embed_size=250, hidden_size=250, num_layers=1, loss_func=<class 'torch.nn.modules.loss.CrossEntropyLoss'>, learning_rate=0.03, optimizer=<class 'torch.optim.adam.Adam'>, batch_size=245)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNd5dglUgy_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training routine.\n",
        "def train(num_epochs, dataloader, model, criterion, optimizer):\n",
        "    losses = []\n",
        "    plt.ion()\n",
        "    for _e in range(num_epochs):\n",
        "        for batch in tqdm(dataloader):\n",
        "            # Zero gradient.\n",
        "            optimizer.zero_grad()\n",
        "            x = batch['x'].to(device)\n",
        "            x_len = batch['x_len'].to(device)\n",
        "            y = batch['y'].to(device)\n",
        "            # Feed forward. \n",
        "            output, hidden = model(x, use_softmax=False)\n",
        "            # Compute loss:\n",
        "            # Shape of the `output` is [batch_size x sequence_len x vocab_size]\n",
        "            # Shape of `y` is [batch_size x sequence_len]\n",
        "            # CrossEntropyLoss expects `output` to be [batch_size x vocab_size x sequence_len]\n",
        "            _, prediction = torch.max(output, dim=2)\n",
        "            loss = criterion(output.permute(0, 2, 1), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.float().data)\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        plt.plot(losses)\n",
        "        plt.pause(0.05)\n",
        "\n",
        "\n",
        "def initialize_data_model_optim_loss(hyperparams):\n",
        "    # Initialize the dataset and dataloader.\n",
        "    kilgariff_data = KilgariffDataset(tokenized_text)\n",
        "    dataloader = DataLoader(dataset=kilgariff_data, \n",
        "                            batch_size=hyperparams.batch_size, \n",
        "                            shuffle=True)\n",
        "\n",
        "    # Loss function.\n",
        "    criterion = hyperparams.loss_func(ignore_index=kilgariff_data.vocab.token2id['<pad>'], \n",
        "                                      reduction='mean')\n",
        "\n",
        "    # Model.\n",
        "    model = Generator(len(kilgariff_data.vocab), hyperparams.embed_size, \n",
        "                      hyperparams.hidden_size, hyperparams.num_layers).to(device)\n",
        "\n",
        "    # Optimizer.\n",
        "    optimizer = hyperparams.optimizer(model.parameters(), lr=hyperparams.learning_rate)\n",
        "    \n",
        "    return dataloader, model, optimizer, criterion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTRsHuGThaWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_example(model, temperature=1.0, max_len=100, hidden_state=None):\n",
        "    start_token, start_idx = '<s>', 2\n",
        "    # Start state.\n",
        "    inputs = torch.tensor(kilgariff_data.vocab.token2id[start_token]).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    sentence = [start_token]\n",
        "    i = 0\n",
        "    while i < max_len and sentence[-1] not in ['</s>', '<pad>']:\n",
        "        i += 1\n",
        "        \n",
        "        embedded = model.embedding(inputs)\n",
        "        output, hidden_state = model.gru(embedded, hidden_state)\n",
        "\n",
        "        batch_size, sequence_len, hidden_size = output.shape\n",
        "        output = output.contiguous().view(batch_size * sequence_len, hidden_size)    \n",
        "        output = model.classifier(output).view(batch_size, sequence_len, -1).squeeze(0)\n",
        "        #_, prediction = torch.max(F.softmax(output, dim=2), dim=2)\n",
        "        \n",
        "        word_weights = output.div(temperature).exp().cpu()\n",
        "        if len(word_weights.shape) > 1:\n",
        "            word_weights = word_weights[-1] # Pick the last word.    \n",
        "        word_idx = torch.multinomial(word_weights, 1).view(-1)\n",
        "        \n",
        "        sentence.append(kilgariff_data.vocab[int(word_idx)])\n",
        "        \n",
        "        inputs = tensor([kilgariff_data.vocab.token2id[word] for word in sentence]).unsqueeze(0).to(device)\n",
        "    print(' '.join(sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7wA6Zu5hgN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "04f85592-dca7-4a95-f0b8-763ae794fd8d"
      },
      "source": [
        "hyperparams = Hyperparams(embed_size=250, hidden_size=250, num_layers=1,\n",
        "                          loss_func=nn.CrossEntropyLoss,\n",
        "                          learning_rate=0.03, optimizer=optim.Adam, batch_size=250)\n",
        "\n",
        "dataloader, model, optimizer, criterion = initialize_data_model_optim_loss(hyperparams)\n",
        "\n",
        "train(100, dataloader, model, criterion, optimizer)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAHUCAYAAADY9fvpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwAsAAABbI/ACAADA1gi8AAAAsLX/H6APB34SoAPcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXF4majHhmMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "4808a6f3-f0df-4105-baa0-1d73c4fda9fe"
      },
      "source": [
        "for _ in range(10):\n",
        "    generate_example(model)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> however this does not factor in the arbitrariness of the word occurring at all in the corpus : in a corpus ten times the size , there would be roughly ten times the number of singletons and doubletons in the corpus , most of which would not have occurred at all in the original corpus . </s>\n",
            "<s> language is never , ever , ever , random adam kilgarriff abstract language users never choose words randomly , and language is essentially non-random . </s>\n",
            "<s> if the likelihood is low , we reject h0. the problem for empirical linguistics is that language is not random , so the null hypothesis is never true . </s>\n",
            "<s> polytech publishers. pedersen , ted 1996 fishing for exactness . </s>\n",
            "<s> harlow : longman. leech , geoffrey and roger fallon 1992 computer corpora — what do they tell us about culture ? </s>\n",
            "<s> we do not always have enough data to reject the null hypothesis , but that is a distinct issue : wherever there is enough data , it is rejected . </s>\n",
            "<s> biometrika 40 , 237⫺264. grefenstette , gregory and julien nioche 2000 estimation of english and non-english language use on the www . </s>\n",
            "<s> rather , the objection is that the probability model , with its assumptions of randomness , is inappropriate , particularly where counts are high ( eg , thousands or more ) . where the task is to determine whether there is an interesting associa- tion between two rare events , dunning ’ s concern must be heeded . </s>\n",
            "<s> however , problems are noted : further evaluation of the results ... reveals that the filtering phase is the weak link in the system … the performance of the filter for classes with less than 10 exemplars is around chance , and a simple heuristic of accepting all classes with more then 10 exemplars would have pro- duced broadly similar results for these verbs ( briscoe and carroll 1997 : 360⫺36 ) . korhonen , correll , and mccarthy ( 2000 ) explore the issue in detail. using briscoe and carroll ’ s scf acquisition system , they explore the\n",
            "<s> one statistics textbook warns thus : none of the null hypotheses we have considered with respect to good- ness of fit can be exactly true , so if we increase the sample size ( and hence the value of χ2 ) we would ultimately reach the point when all null hypotheses would be rejected . </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln7AA2r7h9IF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "torch.save(model.state_dict(), 'gru-model.pth')\n",
        "\n",
        "hyperparams_str = Hyperparams(embed_size=250, hidden_size=250, num_layers=1,\n",
        "                          loss_func='nn.CrossEntropyLoss',\n",
        "                          learning_rate=0.03, optimizer='optim.Adam', batch_size=250)\n",
        "\n",
        "with open('gru-model.json', 'w') as fout:\n",
        "    json.dump(dict(hyperparams_str._asdict()), fout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11TRs3uCiNRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}