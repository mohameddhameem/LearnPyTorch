{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenAI Conversational chatbot.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlUIFEwrCXJx7QlTJozQzn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohameddhameem/NLPWithPyTorch/blob/master/OpenAI_Conversational_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0bINBamXa20",
        "colab_type": "text"
      },
      "source": [
        "# ConvAI with Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsj7yIfpXgwA",
        "colab_type": "text"
      },
      "source": [
        "Original inspiration of this code comes from <br>\n",
        "https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPfZaelEX7xh",
        "colab_type": "text"
      },
      "source": [
        "# How it works\n",
        "![alt text](https://miro.medium.com/max/2070/1*sIRX4M3--Qrvo-RLqH-7GQ.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovYkMopUYvxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "67be4bb2-2802-490b-d53e-6c6bb9b6976d"
      },
      "source": [
        "!pip install -U transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a0/32e3a4501ef480f7ea01aac329a716132f32f7911ef1c2fac228acc57ca7/transformers-2.6.0-py3-none-any.whl (540kB)\n",
            "\u001b[K     |████████████████████████████████| 542kB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.26)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 59.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 61.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.16.0,>=1.15.26 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.26)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.26->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.26->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=5c24f0d430c27e8c476325996212e10f44f622dba7ab0a81b28aba146cd3dc02\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aFWY1YbZBqQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "f88b5d49-6a93-41fe-fa1b-6ce40012f3c8"
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 27.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 32.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 35.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 39.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 42.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 42.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 43.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 46.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 46.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 46.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.12.26)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.11.28)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.26 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.15.26)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.26->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.26->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.26->boto3->pytorch_pretrained_bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgrrAwqsZajA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "eedb1ccf-dac2-443b-9cc5-439310d4d408"
      },
      "source": [
        "!pip install ftfy spacy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d8/5e877ac5e827eaa41a7ea8c0dc1d3042e05d7e337604dc2aedb854e7b500/ftfy-5.7.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 30.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 37.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 41.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 43.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 45.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.1.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.38.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.7-cp36-none-any.whl size=44593 sha256=107f2796843de03e48fcc0800f9f8ef28db85e44a0d8338e4698e185cd8a2c23\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/da/59/6c8925d571aacade638a0f515960c21c0887af1bfe31908fbf\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-5.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGPTNP7mZiga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "e0e3e2f9-ee5e-49c1-d148-82be2a05f391"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.38.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4VCs_KSXPmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from transformers import *\n",
        "from pytorch_pretrained_bert import OpenAIGPTDoubleHeadsModel, OpenAIGPTTokenizer\n",
        "\n",
        "model = OpenAIGPTDoubleHeadsModel.from_pretrained('openai-gpt')\n",
        "tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr3EPIa2YRIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will use 5 special tokens:\n",
        "# - <bos> to indicate the start of the sequence\n",
        "# - <eos> to indicate the end of the sequence\n",
        "# - <speaker1> to indicate the beginning and the tokens of an utterance from the user\n",
        "# - <speaker2> to indicate the beginning and the tokens of an utterance from the bot\n",
        "# - <pad> as a padding token to build batches of sequences\n",
        "SPECIAL_TOKENS = [\"<bos>\", \"<eos>\", \"<speaker1>\", \"<speaker2>\", \"<pad>\"]\n",
        "\n",
        "# We can add these special tokens to the vocabulary and the embeddings of the model:\n",
        "tokenizer.set_special_tokens(SPECIAL_TOKENS)\n",
        "model.set_num_special_tokens(len(SPECIAL_TOKENS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOW8SwVdfvu2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31192d50-530a-4a4a-dfdb-5065de23744e"
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "# Let's define our contexts and special tokens\n",
        "persona = [[\"i\", \"like\", \"playing\", \"football\", \".\"],\n",
        "           [\"i\", \"am\", \"from\", \"NYC\", \".\"]]\n",
        "history = [[\"hello\", \"how\", \"are\", \"you\", \"?\"],\n",
        "           [\"i\", \"am\", \"fine\", \"thanks\", \".\"]]\n",
        "reply = [\"great\", \"to\", \"hear\"]\n",
        "bos, eos, speaker1, speaker2 = \"<bos>\", \"<eos>\", \"<speaker1>\", \"<speaker2>\"\n",
        "\n",
        "def build_inputs(persona, history, reply):\n",
        "    # Build our sequence by adding delimiters and concatenating\n",
        "    sequence = [[bos] + list(chain(*persona))] + history + [reply + [eos]]\n",
        "    sequence = [sequence[0]] + [ [speaker2 if (len(sequence)-i) % 2 else speaker1] + s\n",
        "                                for i, s in enumerate(sequence[1:])]\n",
        "    # Build our word, segments and position inputs from the sequence\n",
        "    words = list(chain(*sequence))                          # word tokens\n",
        "    segments = [speaker2 if i % 2 else speaker1             # segment tokens\n",
        "                for i, s in enumerate(sequence) for _ in s]\n",
        "    position = list(range(len(words)))                      # position tokens\n",
        "    return words, segments, position, sequence\n",
        "\n",
        "words, segments, position, sequence = build_inputs(persona, history, reply)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl1nCfIEf5QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize words and segments embeddings:\n",
        "words = tokenizer.convert_tokens_to_ids(words)\n",
        "segments = tokenizer.convert_tokens_to_ids(segments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NpMovN8gAuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "# Let's add a distractor to our previously defined persona, history and reply\n",
        "distractor = [\"sorry\", \"to\", \"hear\", \"that\"]\n",
        "\n",
        "# Build & tokenize inputs ending with our distractor like we did with the gold reply\n",
        "words_distractor, segments_distractor, _, _ = build_inputs(persona, history, distractor)\n",
        "words_distractor = tokenizer.convert_tokens_to_ids(words_distractor)\n",
        "segments_distractor = tokenizer.convert_tokens_to_ids(segments_distractor)\n",
        "\n",
        "# Prepare our language modeling targets: keep only the reply segment, -1 on the rest\n",
        "lm_targets = ([-1] * sum(len(s) for s in sequence[:-1])) \\\n",
        "             + [-1] + tokenizer.convert_tokens_to_ids(sequence[-1][1:])\n",
        "lm_distractor = [-1] * len(words_distractor)\n",
        "\n",
        "# Store the position of the last tokens for the next-sentence prediction loss\n",
        "last_token = len(words) - 1\n",
        "last_token_distractor = len(words_distractor) - 1\n",
        "\n",
        "# Now we can pad reply and distractor inputs and targets to the same length\n",
        "padding_length = max(len(words), len(words_distractor))\n",
        "def pad(x, padding):\n",
        "    return x + [padding] * (padding_length - len(x))\n",
        "\n",
        "(words, words_distractor,\n",
        " segments, segments_distractor) = [pad(x, tokenizer.convert_tokens_to_ids('<pad>'))\n",
        "                                   for x in (words, words_distractor,\n",
        "                                             segments, segments_distractor)]\n",
        "\n",
        "(lm_targets, lm_distractor) = [pad(x, -1) for x in (lm_targets, lm_distractor)]\n",
        " \n",
        "# And gather reply and distractor inputs to build the input tensors:\n",
        "# words tokens\n",
        "input_ids = torch.tensor([[words, words_distractor]], dtype=torch.long)\n",
        "# segment tokens\n",
        "token_type_ids = torch.tensor([[segments, segments_distractor]], dtype=torch.long)\n",
        "# Positions tokens can be automatically created by the model as (0, 1, ..., N)\n",
        "# Last tokens location\n",
        "mc_token_ids = torch.tensor([[last_token, last_token_distractor]], dtype=torch.long)\n",
        "# Language modeling labels\n",
        "lm_labels = torch.tensor([[lm_targets, lm_distractor]], dtype=torch.long)\n",
        "# Next-sentence prediction labels\n",
        "mc_labels = torch.tensor([0], dtype=torch.long)  # Gold reply is 1st (index 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnCrHsSSgMrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Forward pass\n",
        "lm_loss, mc_loss = model(input_ids, mc_token_ids, lm_labels, mc_labels, token_type_ids)\n",
        "\n",
        "# Total loss as a weighted sum\n",
        "lm_coef = 2.0\n",
        "mc_coef = 1.0\n",
        "total_loss = lm_loss * lm_coef + mc_loss * mc_coef"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsUWao-6gQrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98863f94-08b9-4518-aba4-e9e5e41e644a"
      },
      "source": [
        "import json\n",
        "from pytorch_pretrained_bert import cached_path\n",
        "\n",
        "#url = \"s3://datasets.huggingface.co/personachat/personachat_self_original.json\"\n",
        "url = \"https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json\"\n",
        "\n",
        "# Download and load JSON dataset\n",
        "personachat_file = cached_path(url)\n",
        "with open(personachat_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    dataset = json.loads(f.read())\n",
        "\n",
        "# Tokenize and encode the dataset using our loaded GPT tokenizer\n",
        "def tokenize(obj):\n",
        "    if isinstance(obj, str):\n",
        "        return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(obj))\n",
        "    if isinstance(obj, dict):\n",
        "        return dict((n, tokenize(o)) for n, o in obj.items())\n",
        "    return list(tokenize(o) for o in obj)\n",
        " \n",
        "dataset = tokenize(dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209850483/209850483 [00:04<00:00, 42776429.95B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra64nwszgWB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}