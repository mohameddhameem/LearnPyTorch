{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn BERT with Transformers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXWAvI6+fQ6SUduittMRcu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5134592613c942628548ccfb6558d964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_27599ff2b96b4667a6a3ee87f4ed8115",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d4ba79f814c4e42b12431dc34e34e9c",
              "IPY_MODEL_e5707b1e689e4c8db839f1ba3b4e83ba"
            ]
          }
        },
        "27599ff2b96b4667a6a3ee87f4ed8115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d4ba79f814c4e42b12431dc34e34e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d7cbffb89a55457e82786b5cc088cc10",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5e2ba55f2a34f65abe15106b85da769"
          }
        },
        "e5707b1e689e4c8db839f1ba3b4e83ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_48ac8f35f05d40f2addc149ba41c3c3f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 795kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9601e030d65e4e5084b96ae6a9182985"
          }
        },
        "d7cbffb89a55457e82786b5cc088cc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5e2ba55f2a34f65abe15106b85da769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48ac8f35f05d40f2addc149ba41c3c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9601e030d65e4e5084b96ae6a9182985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bb44854ee644ad3a2713def9e0bfd9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_72bfc165f5414d88bf20124e957b9e12",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_da76e21b3e934ef288337dd94e611b0c",
              "IPY_MODEL_01669627e10d479ebce5fc3b92bd9ba2"
            ]
          }
        },
        "72bfc165f5414d88bf20124e957b9e12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da76e21b3e934ef288337dd94e611b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c94f2988ae645c1bfac0e8df774c039",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_411a165599984bdc893d2229d17c8b92"
          }
        },
        "01669627e10d479ebce5fc3b92bd9ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c04214879a4449eae2602f55915a1a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 361/361 [00:00&lt;00:00, 452B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07f9f4f25b9b4132ba60a59a11c30a41"
          }
        },
        "5c94f2988ae645c1bfac0e8df774c039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "411a165599984bdc893d2229d17c8b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c04214879a4449eae2602f55915a1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07f9f4f25b9b4132ba60a59a11c30a41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b3e55a2ca244c5eb0deb5a66c722526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fa3a8c9f1024ba0a7836eaefa374a72",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5312195503214063a2fa1fea99e1fb13",
              "IPY_MODEL_221962a8b1ab469d9842201251ca39e7"
            ]
          }
        },
        "8fa3a8c9f1024ba0a7836eaefa374a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5312195503214063a2fa1fea99e1fb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85047b32ede0489ab23f83bf1dbee64a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af5ef02c0b404c9eaa8b5abc36e36c3c"
          }
        },
        "221962a8b1ab469d9842201251ca39e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc30a43e99e3438cade090301befeb9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:16&lt;00:00, 27.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_763ca8baefd94f5eacddb9d2470166e2"
          }
        },
        "85047b32ede0489ab23f83bf1dbee64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af5ef02c0b404c9eaa8b5abc36e36c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc30a43e99e3438cade090301befeb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "763ca8baefd94f5eacddb9d2470166e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31a3906df7254e4faffee9fb4fd21650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18b33819fb1d4cb4a5134d824972ce85",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5ca6f2a7d59407a8a4956c553855e3d",
              "IPY_MODEL_180d1576caab404abf49ae5ad3496087"
            ]
          }
        },
        "18b33819fb1d4cb4a5134d824972ce85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5ca6f2a7d59407a8a4956c553855e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8534e52393c9475dbb98566ed7bd36fe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 362,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 362,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f5853f6b37a4746a81df61177c8a96a"
          }
        },
        "180d1576caab404abf49ae5ad3496087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2bca6cc1e1f44f839d334e18b6f278a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 362/362 [02:21&lt;00:00, 2.56B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9d0322e66ea4b99aa882034edba8227"
          }
        },
        "8534e52393c9475dbb98566ed7bd36fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f5853f6b37a4746a81df61177c8a96a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bca6cc1e1f44f839d334e18b6f278a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9d0322e66ea4b99aa882034edba8227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohameddhameem/NLPWithPyTorch/blob/master/Learn_BERT_with_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHjk4zCEREXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW3p9H_ZRSz7",
        "colab_type": "code",
        "outputId": "9f8ab632-5c88-4319-e1aa-433ddae21b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "# Install the additional libaries.\n",
        "! pip install -U git+https://github.com/huggingface/transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-w760l7jy\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-w760l7jy\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (1.18.2)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (1.12.23)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 32.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.1) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.1) (0.9.5)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.16.0,>=1.15.23 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.1) (1.15.23)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.23->boto3->transformers==2.5.1) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.23->boto3->transformers==2.5.1) (0.15.2)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.5.1-cp36-none-any.whl size=534520 sha256=07f75b602b09fef4332680e80de7bf6824a4991a48d09d6ff645863815465042\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5qqu4739/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=eadcf6a5ff338674c8455faae391798c7ee4a298941968b881900dacb59fa970\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfHIOAwZRe4p",
        "colab_type": "code",
        "outputId": "c17c6e07-864a-4fa6-8340-f6ab6397b59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from itertools import chain\n",
        "from collections import namedtuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kH5DxzgRvJw",
        "colab_type": "code",
        "outputId": "c85b2010-1fb8-49c3-a40a-ac092213bb86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "5134592613c942628548ccfb6558d964",
            "27599ff2b96b4667a6a3ee87f4ed8115",
            "2d4ba79f814c4e42b12431dc34e34e9c",
            "e5707b1e689e4c8db839f1ba3b4e83ba",
            "d7cbffb89a55457e82786b5cc088cc10",
            "f5e2ba55f2a34f65abe15106b85da769",
            "48ac8f35f05d40f2addc149ba41c3c3f",
            "9601e030d65e4e5084b96ae6a9182985"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "# A tokenizer will split the text into the appropriate sub-parts (aka. tokens).\n",
        "# Depending on how the pre-trained model is trained, the tokenizers defers.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
        "\n",
        "# Example of a tokenized input after WordPiece Tokenization.\n",
        "text = \"[CLS] my dog is cute [SEP] he likes playing [SEP]\"\n",
        "print(tokenizer.wordpiece_tokenizer.tokenize(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5134592613c942628548ccfb6558d964",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "['[CLS]', 'my', 'dog', 'is', 'cute', '[SEP]', 'he', 'likes', 'playing', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGjaWjRORzRC",
        "colab_type": "code",
        "outputId": "41cec035-ca92-4776-850c-d5e99d2a0726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"playing\" in tokenizer.wordpiece_tokenizer.vocab"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB-vqRQ5R2gT",
        "colab_type": "code",
        "outputId": "894d8ab2-2d86-4c29-b5cb-5cf0611a16f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"slacking\" in tokenizer.wordpiece_tokenizer.vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSR6C1K6S-KF",
        "colab_type": "code",
        "outputId": "620102f9-438d-4f03-d2e8-4a553fe2311a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = \"[CLS] my dog is cute [SEP] he likes slacking [SEP]\"\n",
        "tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(text) # There, we see the ##ing token!\n",
        "print(tokenized_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'my', 'dog', 'is', 'cute', '[SEP]', 'he', 'likes', 'slack', '##ing', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3kCOOXrTQfY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92cf3d9f-d018-4c6c-9f73-2f8f488fbe81"
      },
      "source": [
        "token_indices = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "token_indices"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 2026, 3899, 2003, 10140, 102, 2002, 7777, 19840, 2075, 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G05oFUho0EvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fff37369-7b50-417f-99a9-b39b10ea50aa"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# We need to create an array that indicates the end of sentences, delimited by [SEP]\n",
        "text = \"[CLS] my dog is cute [SEP] he likes slacking [SEP]\"\n",
        "tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(text)  # There, we see the ##ing token!\n",
        "\n",
        "# First we find the indices of `[SEP]`, and incrementally adds it up. \n",
        "# Here's some Numpy gymnastics... \n",
        "# Thanks to @divakar https://stackoverflow.com/a/58316889/610569\n",
        "m = np.asarray(tokenized_text) == \"[SEP]\"\n",
        "segments_ids = m.cumsum()-m\n",
        "\n",
        "tokens_tensor, segments_tensors = torch.tensor([token_indices]), torch.tensor([segments_ids])\n",
        "\n",
        "# See the type change?\n",
        "print(tokens_tensor.shape, type(token_indices), type(tokens_tensor))\n",
        "print(segments_tensors.shape, type(segments_ids), type(segments_tensors))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11]) <class 'list'> <class 'torch.Tensor'>\n",
            "torch.Size([1, 11]) <class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox88a8Sx0LtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cdd72921-ce44-4a3f-d3e8-ceaf25cce7a1"
      },
      "source": [
        "tokens_tensor, segments_tensors = torch.tensor([token_indices]), torch.tensor([segments_ids])\n",
        "\n",
        "# See the type change?\n",
        "print(tokens_tensor.shape, type(token_indices), type(tokens_tensor))\n",
        "print(segments_tensors.shape, type(segments_ids), type(segments_tensors))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11]) <class 'list'> <class 'torch.Tensor'>\n",
            "torch.Size([1, 11]) <class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fg3OBqD0Vmj",
        "colab_type": "text"
      },
      "source": [
        "# Lets convert our input text to an array of number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj6kbYa40Zd5",
        "colab_type": "text"
      },
      "source": [
        "## First, we load the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrg6rWed0Phb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9bb44854ee644ad3a2713def9e0bfd9d",
            "72bfc165f5414d88bf20124e957b9e12",
            "da76e21b3e934ef288337dd94e611b0c",
            "01669627e10d479ebce5fc3b92bd9ba2",
            "5c94f2988ae645c1bfac0e8df774c039",
            "411a165599984bdc893d2229d17c8b92",
            "1c04214879a4449eae2602f55915a1a5",
            "07f9f4f25b9b4132ba60a59a11c30a41",
            "9b3e55a2ca244c5eb0deb5a66c722526",
            "8fa3a8c9f1024ba0a7836eaefa374a72",
            "5312195503214063a2fa1fea99e1fb13",
            "221962a8b1ab469d9842201251ca39e7",
            "85047b32ede0489ab23f83bf1dbee64a",
            "af5ef02c0b404c9eaa8b5abc36e36c3c",
            "cc30a43e99e3438cade090301befeb9f",
            "763ca8baefd94f5eacddb9d2470166e2"
          ]
        },
        "outputId": "a5aca987-dbdc-4aca-bc98-250f693975de"
      },
      "source": [
        "import torch \n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# When using the BERT model for \"encoding\", i.e. convert string to array of floats, \n",
        "# we use the `BertModel` object from pytorch transformer library.\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.eval(); model.to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bb44854ee644ad3a2713def9e0bfd9d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b3e55a2ca244c5eb0deb5a66c722526",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQIQTyTQ0d93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f3fa3043-8dcf-4d7c-a746-2c326c94607c"
      },
      "source": [
        "# Predict hidden states features for each layer\n",
        "with torch.no_grad():\n",
        "    encoded_layers, _ = model(tokens_tensor.to(device), segments_tensors.to(device))\n",
        "    \n",
        "print(encoded_layers)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0737,  0.1229, -0.1612,  ...,  0.1235,  0.2381,  0.0880],\n",
            "         [ 0.5442,  0.6884, -0.0744,  ..., -0.0346,  0.1388, -0.4474],\n",
            "         [ 0.7117,  0.6298, -0.0084,  ...,  0.1541,  0.1260, -0.1969],\n",
            "         ...,\n",
            "         [ 0.6583,  0.4991, -0.1022,  ...,  0.2715, -0.2863, -0.4839],\n",
            "         [-0.1440, -0.3067, -0.3331,  ...,  0.4313,  0.1080,  0.0214],\n",
            "         [ 0.9325,  0.2506,  0.0805,  ...,  0.1434, -0.8708, -0.4659]]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nwj25zJ0xxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6da1690e-2113-4587-a327-f9c8466989ca"
      },
      "source": [
        "encoded_layers.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 11, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcpz1OWV07O9",
        "colab_type": "text"
      },
      "source": [
        "# The BERT model is very good at fill-in-the-blank task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-QdA9Qi0-AB",
        "colab_type": "text"
      },
      "source": [
        "The BERT model is trained using a \"cloze\" task where words are randomly replaced with the [MASK] symbols and the model learns to adjust its parameters such that it learns which words are most probable to fit into the [MASK] symbols.\n",
        "\n",
        "When using the BERT model for \"guessing missing words\", we use the BertForMaskedLM object from pytorch transformer library. Here's an example if we blank out words in the sentence, BERT is able to find the appropriate word to fill it in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0gfue6i04Ez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3109c6bd-92f0-43e8-a45e-cde2683abdf8"
      },
      "source": [
        "# Load the model.\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "model.eval(); model.to(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXe-OFNX1A4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fedccfde-75ff-45bb-a0f6-9f6e0c9b47db"
      },
      "source": [
        "# We need to create an array that indicates the end of sentences, delimited by [SEP]\n",
        "text = \"[CLS] please don't let the [MASK] out of the [MASK] . [SEP]\"\n",
        "tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(text)\n",
        "token_indices = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# Create the segment indices.\n",
        "m = np.asarray(tokenized_text) == \"[SEP]\"\n",
        "segments_ids = m.cumsum()-m\n",
        "\n",
        "# Convert them to the arrays to pytorch tensors.\n",
        "tokens_tensor, segments_tensors = torch.tensor([token_indices]), torch.tensor([segments_ids])\n",
        "\n",
        "# Apply the model to the inputs.\n",
        "with torch.no_grad(): # You can take this context manager to mean that we're not training.\n",
        "    outputs, *_ = model(tokens_tensor.to(device), \n",
        "                        token_type_ids=segments_tensors.to(device))\n",
        "\n",
        "outputs.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 14, 30522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWuXanKp1QL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the model to the inputs.\n",
        "with torch.no_grad(): # You can take this context manager to mean that we're not training.\n",
        "    outputs, *_ = model(tokens_tensor.to(device), token_type_ids=segments_tensors.to(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znbaWWPK1TJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66aef2ca-4b84-4846-b3be-2615fa7481e5"
      },
      "source": [
        "outputs.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 14, 30522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSbSuHga1VXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5414ce81-371d-4fc5-f945-3ccbc01c3e00"
      },
      "source": [
        "print(tokenized_text)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'please', 'don', \"##'\", '##t', 'let', 'the', '[MASK]', 'out', 'of', 'the', '[MASK]', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3-IZWwP1YlT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cb09053-2065-4c10-9cc3-084d283145d0"
      },
      "source": [
        "# Lets remember our original masked sentence.\n",
        "print(tokenized_text)\n",
        "# We have to check where the masked token is from the original text. \n",
        "mask_index = tokenized_text.index('[MASK]') \n",
        "assert mask_index == 7 # The 7th token.\n",
        "\n",
        "# Then we fetch the vector for the 7th value, \n",
        "# The [0, mask_index] refers to accessing vector of vocab_size for\n",
        "# the 0th sentence, mask_index-th token.\n",
        "output_value = outputs[0, mask_index]\n",
        "\n",
        "# As a sanity check we can see that the shape of the output_value\n",
        "# is the same as the `vocab_size` from the outputs' shape.\n",
        "assert int(output_value.shape[0]) == len(tokenizer.wordpiece_tokenizer.vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'please', 'don', \"##'\", '##t', 'let', 'the', '[MASK]', 'out', 'of', 'the', '[MASK]', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vmIrzkF1hx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b2f982f7-25dc-4307-f5ac-d608ffab383a"
      },
      "source": [
        "# Lets recap the original sentence with the masked word.\n",
        "print(text)\n",
        "\n",
        "# We have to check where the first masked token is from the original text. \n",
        "mask_index = tokenized_text.index('[MASK]') \n",
        "output_value = outputs[0, mask_index]\n",
        "\n",
        "## We use torch.argmax to get the index with the highest value.\n",
        "mask_word_in_vocab = int(torch.argmax(output_value))\n",
        "print(tokenizer.convert_ids_to_tokens([mask_word_in_vocab]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] please don't let the [MASK] out of the [MASK] . [SEP]\n",
            "['cat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0PXY1dY1llT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b104d285-87a0-4195-c8ef-065582baa048"
      },
      "source": [
        "# Lets recap the original sentence with the masked word.\n",
        "print(text)\n",
        "\n",
        "# We have to check where the masked tokens are from the original text. \n",
        "for mask_index, token in enumerate(tokenized_text):\n",
        "    if token == '[MASK]':\n",
        "        output_value = outputs[0, mask_index]\n",
        "        mask_word_in_vocab = int(torch.argmax(output_value))\n",
        "        print(tokenizer.convert_ids_to_tokens([mask_word_in_vocab]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] please don't let the [MASK] out of the [MASK] . [SEP]\n",
            "['cat']\n",
            "['way']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S6Np96n1wzY",
        "colab_type": "text"
      },
      "source": [
        "# Lets make the fill-in-the-blank feature into a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UojiH7zY1smz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fill_in_the_blanks(text, model, tokenizer, return_str=False):\n",
        "    tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(text)\n",
        "    token_indices = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    # Create the segment indices.\n",
        "    m = np.asarray(tokenized_text) == \"[SEP]\"\n",
        "    segments_ids = m.cumsum()-m\n",
        "    # Convert them to the arrays to pytorch tensors.\n",
        "    tokens_tensor = torch.tensor([token_indices]).to(device)\n",
        "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
        "    \n",
        "    # Apply the model to the inputs.\n",
        "    with torch.no_grad(): # You can take this context manager to mean that we're not training.\n",
        "        outputs, *_ = model(tokens_tensor, token_type_ids=segments_tensors)\n",
        "    \n",
        "    output_tokens = []\n",
        "    for mask_index, token_id in enumerate(token_indices):\n",
        "        token = tokenizer.convert_ids_to_tokens([token_id])[0]\n",
        "        if token == '[MASK]':\n",
        "            output_value = outputs[0, mask_index]\n",
        "            # The masked word index in the vocab.\n",
        "            mask_word_in_vocab = int(torch.argmax(output_value))\n",
        "            token = tokenizer.convert_ids_to_tokens([mask_word_in_vocab])[0]\n",
        "        output_tokens.append(token)\n",
        "        \n",
        "    return \" \".join(output_tokens).replace(\" ##\", \"\").replace(\" ' t \", \"'t \") if return_str else output_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ-bUp8o10YY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76fee5c6-90f7-4220-ff23-9db03e8a5e97"
      },
      "source": [
        "# Load the model.\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "model.eval(); model.to(device)\n",
        "\n",
        "text = \"[CLS] please don't let the [MASK] out of the [MASK] . [SEP]\"\n",
        "print(fill_in_the_blanks(text, model, tokenizer, return_str=True))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] please don't let the cat out of the way . [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edkn6ZX-12rr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58b4dbaa-0b21-4e93-f76a-db67fbc68b00"
      },
      "source": [
        "text = \"[CLS] i like to drink beer and eat [MASK] . [SEP]\"\n",
        "print(fill_in_the_blanks(text, model,tokenizer, return_str=True))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] i like to drink beer and eat meat . [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAmsdGhD16ik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "848d76ee-3552-4881-c57d-7717eb1ae786"
      },
      "source": [
        "text = \"[CLS] i like to drink coffee and eat [MASK] . [SEP]\"\n",
        "print(fill_in_the_blanks(text, model, tokenizer, return_str=True))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] i like to drink coffee and eat it . [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iMJqAcZlLq-",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tuning BERT models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlaZELtP19-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phoenix_turtle = \"\"\"Truth may seem but cannot be;\\nBeauty brag but ’tis not she;\\nTruth and beauty buried be.\"\"\"\n",
        "sonnet20 = \"\"\"A woman’s face with Nature’s own hand painted\\nHast thou, the master-mistress of my passion;\\nA woman’s gentle heart, but not acquainte\\nWith shifting change, as is false women’s fashion;\"\"\"\n",
        "sonnet1 = \"\"\"From fairest creatures we desire increase,\\nThat thereby beauty’s rose might never die,\\nBut as the riper should by time decease,\\nHis tender heir might bear his memory:\"\"\"\n",
        "sonnet73 = \"\"\"In me thou see’st the glowing of such fire,\\nThat on the ashes of his youth doth lie,\\nAs the death-bed whereon it must expire,\\nConsum’d with that which it was nourish’d by.\"\"\"\n",
        "venus_adonis = \"\"\"It shall be cause of war and dire events,\\nAnd set dissension ‘twixt the son and sire;\\nSubject and servile to all discontents,\\nAs dry combustious matter is to fire:\\nSith in his prime Death doth my love destroy,\\nThey that love best their loves shall not enjoy\\n\"\"\"\n",
        "sonnet29 = \"\"\"When, in disgrace with fortune and men’s eyes,\\nI all alone beweep my outcast state,\\nAnd trouble deaf heaven with my bootless cries,\\nAnd look upon myself and curse my fate,\"\"\"\n",
        "sonnet130 = \"\"\"I have seen roses damask’d, red and white,\\nBut no such roses see I in her cheeks;\\nAnd in some perfumes is there more delight\\nThan in the breath that from my mistress reeks.\"\"\"\n",
        "sonnet116 = \"\"\"Love’s not Time’s fool, though rosy lips and cheeks\\nWithin his bending sickle’s compass come;\\nLove alters not with his brief hours and weeks,\\nBut bears it out even to the edge of doom.\"\"\"\n",
        "sonnet18 = \"\"\"But thy eternal summer shall not fade\\nNor lose possession of that fair thou ow’st;\\nNor shall Death brag thou wander’st in his shade,\\nWhen in eternal lines to time thou grow’st;\\nSo long as men can breathe or eyes can see,\\nSo long lives this, and this gives life to thee.\"\"\"\n",
        "anthony_cleo = \"\"\"She made great Caesar lay his sword to bed;\\nHe plowed her, and she cropped.\"\"\"\n",
        "\n",
        "shakespeare = [phoenix_turtle, sonnet20, sonnet1, sonnet73, venus_adonis,\n",
        "              sonnet29, sonnet130, sonnet116, sonnet18, anthony_cleo]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNGMwcRElR3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "31a3906df7254e4faffee9fb4fd21650",
            "18b33819fb1d4cb4a5134d824972ce85",
            "c5ca6f2a7d59407a8a4956c553855e3d",
            "180d1576caab404abf49ae5ad3496087",
            "8534e52393c9475dbb98566ed7bd36fe",
            "8f5853f6b37a4746a81df61177c8a96a",
            "2bca6cc1e1f44f839d334e18b6f278a2",
            "a9d0322e66ea4b99aa882034edba8227"
          ]
        },
        "outputId": "3749989c-48a0-4bf3-9eb1-7758817a033e"
      },
      "source": [
        "from transformers import BertConfig, BertForMaskedLM, BertTokenizer\n",
        "\n",
        "# Load the BERT model.\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "model.eval()\n",
        "model.to(device)\n",
        "# Load the BERT Tokenizer.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
        "# Load the BERT Config.\n",
        "config = BertConfig.from_pretrained('bert-large-uncased')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31a3906df7254e4faffee9fb4fd21650",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=362, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb77M0ESlWkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06f42d28-82b0-4877-ab71-b6081340e7ce"
      },
      "source": [
        "truth = \"that on the ashes of his youth doth lie\"\n",
        "masked_text = \"[CLS] that on the ashes of his youth [MASK] lie\"\n",
        "print(fill_in_the_blanks(masked_text, model, tokenizer, return_str=True))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] that on the ashes of his youth , lie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLXaH1_8l2q9",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Data set for custom text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TakeEjhUlb5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer):\n",
        "        \"\"\"\n",
        "        :param texts: A list of documents, each document is a list of strings.\n",
        "        :rtype texts: list(string)\n",
        "        \"\"\"\n",
        "        tokenization_process = lambda s: tokenizer.build_inputs_with_special_tokens(\n",
        "                                             tokenizer.convert_tokens_to_ids(\n",
        "                                                 tokenizer.tokenize(s.lower())))\n",
        "        pad_sent = lambda x: np.pad(x, (0,tokenizer.max_len_single_sentence - len(x)), 'constant', \n",
        "                                    constant_values=tokenizer.convert_tokens_to_ids(tokenizer.pad_token))\n",
        "        self.examples = torch.tensor([pad_sent(tokenization_process(doc)) for doc in texts])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return torch.tensor(self.examples[item])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3e_SB9sl0rR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the Dataset object.\n",
        "train_dataset = TextDataset(shakespeare, tokenizer)\n",
        "# Initalize the DataLoader object, `batch_size=2` means reads 2 poems at a time.\n",
        "dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peFcMDx_l84a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c77ab7e-db02-4326-f0b3-073475a1f55a"
      },
      "source": [
        "# 10 poems with 510 tokens per poems, \n",
        "# if poem has <510, pad with the 0th index.\n",
        "train_dataset.examples.shape\n",
        "\n",
        "# For each batch, we read 2 poems at a time.\n",
        "print(next(iter(dataloader)).shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 510])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r0ebpF3mE_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "15d3fbed-4f4c-4da3-91f2-64fb1f62e77b"
      },
      "source": [
        "# An example of a batch.\n",
        "next(iter(dataloader))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 1037, 2450,  ...,    0,    0,    0],\n",
              "        [ 101, 2009, 4618,  ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjd295em5Hp",
        "colab_type": "text"
      },
      "source": [
        "## Mask Tokens in Random - 10% of the time it'll random replace the masked word with another word, and 10% of the time it'll keep the original\n",
        "\n",
        "https://github.com/huggingface/transformers/blob/master/examples/run_lm_finetuning.py#L143"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMIGxEMmmIaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_tokens(inputs, tokenizer, mlm_probability=0.8):\n",
        "    \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n",
        "\n",
        "    if tokenizer.mask_token is None:\n",
        "        raise ValueError(\n",
        "            \"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"\n",
        "        )\n",
        "\n",
        "    labels = inputs.clone()\n",
        "    # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
        "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
        "    special_tokens_mask = [\n",
        "        tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
        "    ]\n",
        "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
        "    if tokenizer._pad_token is not None:\n",
        "        padding_mask = labels.eq(tokenizer.pad_token_id)\n",
        "        probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
        "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
        "\n",
        "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
        "\n",
        "    # 10% of the time, we replace masked input tokens with random word\n",
        "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
        "    inputs[indices_random] = random_words[indices_random]\n",
        "\n",
        "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "    return inputs, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmaIU2r9n-vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers.optimization import AdamW\n",
        "from transformers.optimization import get_linear_schedule_with_warmup as WarmupLinearSchedule\n",
        "\n",
        "Arguments = namedtuple('Arguments', ['learning_rate', 'weight_decay', 'adam_epsilon', 'num_warmup_steps', \n",
        "                                     'max_steps', 'num_train_epochs'])\n",
        "\n",
        "args = Arguments(learning_rate=5e-3, weight_decay=0.0, adam_epsilon=1e-8, num_warmup_steps=0, # Optimizer arguments\n",
        "                 max_steps=20, num_train_epochs=50  # Training routine arugments\n",
        "                )  \n",
        "\n",
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "scheduler = WarmupLinearSchedule(optimizer, num_warmup_steps=args.num_warmup_steps, num_training_steps=args.max_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvg5qo6eoJgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "5cf11a67-8549-4bd6-9b59-25240f9ff2fb"
      },
      "source": [
        "for _e in range(args.num_train_epochs):\n",
        "    print('Epoch:', _e, '\\t' ,end='')\n",
        "    for step, batch in enumerate(iter(dataloader)):\n",
        "        print(step, end=', ')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Randomly mask the tokens 80% of the time. \n",
        "        inputs, labels = mask_tokens(batch, tokenizer)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Initialize the model to train mode.\n",
        "        model.train()\n",
        "        # Feed forward the inputs through the models.\n",
        "        loss, _ = model(inputs, masked_lm_labels=labels)\n",
        "\n",
        "        # Backpropagate the loss.\n",
        "        loss.backward()\n",
        "        # Step through the optimizer.\n",
        "        optimizer.step()\n",
        "    print()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \t0, 1, 2, 3, 4, \n",
            "Epoch: 1 \t0, 1, 2, 3, 4, \n",
            "Epoch: 2 \t0, 1, 2, 3, 4, \n",
            "Epoch: 3 \t0, 1, 2, 3, 4, \n",
            "Epoch: 4 \t0, 1, 2, 3, 4, \n",
            "Epoch: 5 \t0, 1, 2, 3, 4, \n",
            "Epoch: 6 \t0, 1, 2, 3, 4, \n",
            "Epoch: 7 \t0, 1, 2, 3, 4, \n",
            "Epoch: 8 \t0, 1, 2, 3, 4, \n",
            "Epoch: 9 \t0, 1, 2, 3, 4, \n",
            "Epoch: 10 \t0, 1, 2, 3, 4, \n",
            "Epoch: 11 \t0, 1, 2, 3, 4, \n",
            "Epoch: 12 \t0, 1, 2, 3, 4, \n",
            "Epoch: 13 \t0, 1, 2, 3, 4, \n",
            "Epoch: 14 \t0, 1, 2, 3, 4, \n",
            "Epoch: 15 \t0, 1, 2, 3, 4, \n",
            "Epoch: 16 \t0, 1, 2, 3, 4, \n",
            "Epoch: 17 \t0, 1, 2, 3, 4, \n",
            "Epoch: 18 \t0, 1, 2, 3, 4, \n",
            "Epoch: 19 \t0, 1, 2, 3, 4, \n",
            "Epoch: 20 \t0, 1, 2, 3, 4, \n",
            "Epoch: 21 \t0, 1, 2, 3, 4, \n",
            "Epoch: 22 \t0, 1, 2, 3, 4, \n",
            "Epoch: 23 \t0, 1, 2, 3, 4, \n",
            "Epoch: 24 \t0, 1, 2, 3, 4, \n",
            "Epoch: 25 \t0, 1, 2, 3, 4, \n",
            "Epoch: 26 \t0, 1, 2, 3, 4, \n",
            "Epoch: 27 \t0, 1, 2, 3, 4, \n",
            "Epoch: 28 \t0, 1, 2, 3, 4, \n",
            "Epoch: 29 \t0, 1, 2, 3, 4, \n",
            "Epoch: 30 \t0, 1, 2, 3, 4, \n",
            "Epoch: 31 \t0, 1, 2, 3, 4, \n",
            "Epoch: 32 \t0, 1, 2, 3, 4, \n",
            "Epoch: 33 \t0, 1, 2, 3, 4, \n",
            "Epoch: 34 \t0, 1, 2, 3, 4, \n",
            "Epoch: 35 \t0, 1, 2, 3, 4, \n",
            "Epoch: 36 \t0, 1, 2, 3, 4, \n",
            "Epoch: 37 \t0, 1, 2, 3, 4, \n",
            "Epoch: 38 \t0, 1, 2, 3, 4, \n",
            "Epoch: 39 \t0, 1, 2, 3, 4, \n",
            "Epoch: 40 \t0, 1, 2, 3, 4, \n",
            "Epoch: 41 \t0, 1, 2, 3, 4, \n",
            "Epoch: 42 \t0, 1, 2, 3, 4, \n",
            "Epoch: 43 \t0, 1, 2, 3, 4, \n",
            "Epoch: 44 \t0, 1, 2, 3, 4, \n",
            "Epoch: 45 \t0, 1, 2, 3, 4, \n",
            "Epoch: 46 \t0, 1, 2, 3, 4, \n",
            "Epoch: 47 \t0, 1, 2, 3, 4, \n",
            "Epoch: 48 \t0, 1, 2, 3, 4, \n",
            "Epoch: 49 \t0, 1, 2, 3, 4, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXAvqNWgoXfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93611534-8e7b-460d-d5fe-8c41780ea2f0"
      },
      "source": [
        "truth = \"That on the ashes of his youth doth lie\"\n",
        "masked_text = \"[CLS] That on the ashes of his youth [MASK] lie [SEP]\"\n",
        "print(fill_in_the_blanks(masked_text, model, tokenizer, return_str=True))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [UNK] on the ashes of his youth , lie [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyCzNinZotyR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "14402e37-7b64-4bd2-d1ec-2736432297c4"
      },
      "source": [
        "labels"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100, 2293, 1521,  ..., -100, -100, -100],\n",
              "        [-100, 2021, -100,  ..., -100, -100, -100]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lvQ1SYDpEI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c9f24856-9388-4e3c-c9b1-c500d45d1f75"
      },
      "source": [
        "labels.to(device)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100, 2293, 1521,  ..., -100, -100, -100],\n",
              "        [-100, 2021, -100,  ..., -100, -100, -100]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2hbhUWNpH86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8964d002-3e20-4b87-e7b0-f12d840270e8"
      },
      "source": [
        "inputs[1][0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(101, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wnapIE6pK8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}